  \section{Ausgangssituation}
   \label{sec:ausgang}
    Zur Erinnerung: Wir wollen für $n \in \N_{\geq 2}$ die wechselseitigen Gravitationskräfte von $n$ Himmelskörpern berechnen. Da die größten davon die Sonnen sind und es davon bereits mehr als
    genug in unserer Galaxie gibt, beschränken wir uns zunächst auf diese. Die Menge unserer $n$ Sonnen ist im Folgenden mit der Menge $\Omega$ dargestellt. Für jede Sonne
    $x \in \Omega$ muss die Gleichung
    \begin{equation}
      f_x = \sum_{\substack{y \in \Omega \\ y \neq x}} \gamma m_x  m_y \frac{y - x}{\norm{y - x}^3_2}
      \label{eq:sum_grav2}
    \end{equation}
    gelöst werden. Zunächst möchte ich die Grundstruktur des Programms vorstellen. Das Programm ist in C geschrieben und wurde in der nicht-optimierten Version von Sven 
    Christophersen zur Verfügung gestellt.
    
    Wir benötigen als ersten Schritt eine Datenstruktur, die unsere Sonnen darstellt. Diese ist in \autoref{lst:bodies} aufgeführt.
    \begin{figure}[tb]
    \centering
    \begin{subfigure}{0.9 \textwidth}
    \begin{lstlisting}[language=C, label=lst:bodies, caption={Die Struktur \code{bodies} dient der Speicherung aller mit den einzelnen Sonnen zusammenhängenden Daten.}, numbers=none]
/* Struct that holds coordinates x, masses m and forces F for all particles. */
struct _bodies {
  int    *id; // id to identify each single body
  double *x;  // x-components of the masses.
  double *y;  // y-components of the masses.
  double *z;  // z-components of the masses.
  double *Fx; // x-components of the forces.
  double *Fy; // y-components of the forces.
  double *Fz; // z-components of the forces.
  double *vx; // x-components of the velocities.
  double *vy; // y-components of the velocities.
  double *vz; // z-components of the velocities.
  double *m;  // The masses.
  int     n;  // Number of masses.
  double th;  // length of one timestep.
};
typedef struct _bodies bodies;
    \end{lstlisting}
    \end{subfigure}
    \end{figure}
    In Vorbereitung einer eventuell anschließenden Vektorisierung (vgl. \todo{Ref auf Ausblick}) wurde diese Struktur als \hyperref[w:aos]{struct of arrays} (vgl. \autoref{sec:processor}) 
    angelegt.
    
    Die Komponenten der Struktur sind:
    \begin{enumerate}
     \item das Array \code{int *id}, das einer einfachen Identifizierung der Sonnen dient,
     \item die Arrays \code{double *x, *y, *z}, in denen die Position der Sonnen gespeichert werden,
     \item die Arrays \code{double *Fx, *Fy, *Fz}, in denen die Kraftvektoren, die auf die einzelnen Sonne wirken, gespeichert werden,
     \item die Arrays \code{double *vx, *vy, *vz}, in denen der Geschwindigkeitsvektor jeder Sonne gespeichert wird,
     \item das Array \code{double *m}, in dem die Massen der Sonnen gespeichert werden, und zuletzt
     \item die Werte \code{int n} und \code{double th}, die die Anzahl an Sonnen und die Länge eines Zeitschritts in Sekunden enthalten.
    \end{enumerate}
    
    Die Körper entsprechen keinen reellen Himmelkörpern, zu denen uns keine Daten vorliegen, sondern werden zufällig generiert. Die Sonnen werden in einem Gebiet von $\pm 1$ Lichtjahr in
    jeder Koordinatenrichtung um einen angenommenen Ursprung mit Massen zwischen einer und $15$ Sonnenmassen verteilt.\todo{echte Werte nachlesen!}

    Um nun alle gravitationellen Wechselwirkungen zu berechnen wird die Methode \code{compute_forces_bodies(...)} (vgl. \autoref{lst:compfbodies}) ausgeführt.
    Gut zu erkennen ist die matrixähnliche Struktur: Die beiden \code{for}-Schleifen entsprechen dem zeilen- und spaltenweisen Durchgehen der zugehörigen $\Omega \times \Omega$-Matrix. 
    Explizit aufgestellt wird diese Matrix allerdings nicht, da dies in Bezug auf den Speicherplatz äußerst ineffizient wäre. Statt dessen wird direkt, wie in \autoref{eq:sum_grav2}
    angegeben, die kumulative Kraftwirkung für jede Sonne berechnet und in der \code{bodies}-Struktur gespeichert. Ein Teil der Kernfunktion ist in den Aufruf von \code{calc\_potential(...)}
    in Zeile 19 ausgegliedert. 
    Diese Methode berechnet das rein auf der Entfernung der beiden Sonnen beruhende Gravitationspotential $P(x,y)$, sodass die Formel aus \autoref{eq:sum_grav2} wie folgt dargestellt werden kann:
    \[
      f_x = \sum_{\substack{y \in \Omega \\ y \neq x}} \gamma m_x  m_y P(x, y), \ \ \ \ P(x, y) := \frac{y - x}{\norm{y - x}^3_2}.
    \]
    
    Wie bereits in der Einleitung beschrieben ist das Problem mit diesem Algorithmus, dass er in Bezug auf die Laufzeit quadratisch skaliert. Läuft dieser Algorithmus mit $n = 2^{13} \approx 8.000$
    Sonnen noch in $1,097$ Sekunden durch, so braucht er bereits für $n = 2^{15} \approx 32.000$ Sonnen $17,531$ Sekunden und für $n = 2^{16} \approx 64.000$ Sonnen bereits über $70$ 
    Sekunden.\footnote{Ausgeführt auf einem Computer mit 16 Gb Arbeitsspeicher und einem Intel Core i7-4710HQ.} 
    Und diese Größenordnung ist weit entfernt von dem reellen Problem, die Gravitationskräfte in unserer Galaxie mit etwa $100.000.000.000$ Sonnen zu berechnen.
    
    \begin{figure}[b]
    \centering
    \begin{subfigure}{0.9\textwidth}
    \begin{lstlisting}[language=C, label=lst:compfbodies,caption={Diese Methode berechnet die auftretenden Gravitationskräfte.}]
/* Computation of the resulting forces for every particle.*/
void compute_forces_bodies(bodies *b) {
  int n = b->n;
  int i, j;
  double F[3],P[3];
  double *x, *y, *z, *m;
  x = b->x;
  y = b->y;
  z = b->z;
  m = b->m;
  for (i = 0; i < n; ++i) {
    F[0] = 0.0;
    F[1] = 0.0;
    F[2] = 0.0;
    for (j = 0; j < n; ++j) {
      if (i == j) {
	continue;
      }
      calc_potential(x[i], y[i], z[i], x[j], y[j], z[j], P);
      F[0] += m[j] * P[0];
      F[1] += m[j] * P[1];
      F[2] += m[j] * P[2];
    }
    b->Fx[i] += GAMMA * m[i] * F[0];
    b->Fy[i] += GAMMA * m[i] * F[1];
    b->Fz[i] += GAMMA * m[i] * F[2];
  }
}
    \end{lstlisting}
    \end{subfigure}
    \end{figure}
    
    \clearpage
    
  \section{$\mathcal{H}^2$-Matrixstruktur und Approximation}
  \label{sec:approxf}
    Nun wollen wir die in \autoref{sec:h2} vorgestellte Struktur der hierarchischen Matrizen nutzen, um den Algorithmus zu beschleunigen. Wir wollen also die Kernfunktion
    \[
     f: \Omega \times \Omega \to \R^3, \ (x,y) \mapsto \gamma m_x  m_y \frac{y - x}{\norm{y - x}^3_2}
    \]
    durch Lagrange-Interpolation der Ordnung $k$ in jeder Koordinatenrichtung auf Clustern $\tau$ und $\sigma$ des zulässigen Blocks $b = \tau \times \sigma \in \mathcal{L}^+(T_{\Omega \times \Omega})$ 
    approximieren.
    Dazu konstruieren wir Tschebyscheff-Interpolationspunkte $\xi_{\mathfrak{g}, \mathfrak{i}} \text{, } \mathfrak{g} \in \{ \tau, \sigma \}, \mathfrak{i} \in \haken{k}^3 =: M \subset \N^3$
    und erhalten so:
    \begin{align*}
      f(x,y) \approx \tilde f (x,y) 
      &= \sum_{\nu \in M} \sum_{\mu \in M} \lag_\indt{\nu}(x) \gamma m_x m_y \frac{\xi_\inds{\mu} - \xi_\indt{\nu}}{\norm{\xi_\inds{\mu} - \xi_\indt{\nu}}^3_2} \lag_\inds{\mu}(y)\\
      &= \gamma \sum_{\nu \in M} \lag_\indt{\nu}(x) m_x \sum_{\mu \in M} \frac{\xi_\inds{\mu} - \xi_\indt{\nu}}{\norm{\xi_\inds{\mu} - \xi_\indt{\nu}}^3_2} \lag_\inds{\mu}(y) m_y\\
      &= \gamma \sum_{\nu \in M} \lag_\indt{\nu}(x) m_x \sum_{\mu \in M} P( \xi_\indt{\nu} , \xi_\inds{\mu} ) \lag_\inds{\mu}(y) m_y.
    \end{align*}
    Anders ausgedrückt wollen wir die Matrix $(F)_{x,y} := f(x,y)$ durch eine $\mathcal{H}^2$-Matrix $\tilde F$ approximieren. Für einen streng zulässigen Blockbaum $T_{\Omega \times \Omega}$ 
    und jeden zulässigen Block $b = \tau \times \sigma \in \mathcal{L}^+(T_{\Omega \times \Omega})$ konstruieren wir die nötigen Matrizen mit $\mu,\nu \in M$ wie folgt:
    \begin{align}
      E_{\tilde \tau} &:=
	(E_{\tilde \tau})_{\mu \nu} := \lag_\indt{\nu}(\xi_{\tilde \tau, \mu}) \ \ \ \, \text{ für alle } \tilde \tau \in sons(\tau) \text{ falls } \tau \notin \mathcal{L}(T_\Omega), \nonumber\\
      V_\tau &:=
      \begin{cases}
	(V_\tau)_{x \nu}   := \lag_\indt{\nu}(x) & \ \text{ für alle } x \in \tau \text{ falls } \tau \in \mathcal{L}(T_\Omega),\\
	\sum_{\tilde \tau \in sons(\tau)} E_{\tilde \tau} V_{\tilde \tau}  & \ \text{ falls } \tau \notin \mathcal{L}(T_\Omega),\\
      \end{cases}\label{eq:vtau}\\
      S_b &:= (S_b)_{\mu \nu} := P( \xi_\indt{\nu} , \xi_\inds{\mu} ), \nonumber\\
      E_{\tilde \sigma} &:=
	(E_{\tilde \sigma})_{\mu \nu} := \lag_\inds{\nu}(\xi_{\tilde \sigma, \mu}) \ \ \ \; \text{ für alle } \tilde \sigma \in sons(\sigma) \text{ falls } \tau \notin \mathcal{L}(T_\Omega), \nonumber\\
      W_\sigma &:=
      \begin{cases}
	(W_\sigma)_{y \nu}   := \lag_\inds{\nu}(y) & \ \text{ für alle } y \in \sigma \text{ falls } \sigma \in \mathcal{L}(T_\Omega),\\
	\sum_{\tilde \sigma \in sons(\sigma)} E_{\tilde \sigma} W_{\tilde \sigma}  & \ \text{ falls } \sigma \notin \mathcal{L}(T_\Omega).\\
      \end{cases}\label{eq:wsigma}      
    \end{align}
    Für die unzulässigen Blöcke $b = \tau \times \sigma \in \mathcal{L}^-(T_{\Omega \times \Omega})$ müssen wir weiterhin vollbesetzte Matrizen
    \[
      N_b := (N_b)_{xy} := \gamma m_x  m_y P(x, y)
    \]
    auswerten.

    Für die Anschauung mag es helfen, sich die Faktoren $\lag_\indt{\nu} m_x =: h_x$ beziehungsweise $\lag_\inds{\mu} m_y =: h_y$ als Anteil der Masse der Sonne $x$ beziehungsweise $y$ an 
    \wlabel{\textit{Ersatzmassen}}{w:ersatzmassen} $m_{\xi_{\mathfrak{g}, \mathfrak{i}}}$ vorzustellen, wobei $\mathfrak{g} \in \{\tau, \sigma\}$ und $\mathfrak{i} \in M$ gilt.
    Durch die Interpolation werden also für weit genug entfernte Gebiete statt der echten Sonnen Ersatzkörper betrachtet, die sich an der Position der Interpolationspunkte befinden 
    und eben diese Ersatzmassen haben. 
%     Die Lagrange-Polynome gewichten also den Anteil der Masse einer Sonne an einer Ersatzmasse.
    
    \subsection{Clusterung}
    Für die oben beschriebene Approximation müssen wir einen Clusterbaum und einen streng zulässigen Blockbaum konstruieren.
    Dazu benötigen wir zunächst eine Datenstruktur für Clusterbäume. Diese sind in \autoref{lst:cluster} zu finden.
    \begin{figure}[tb]
    \begin{subfigure}{0.9\textwidth}
    \begin{lstlisting}[language=C, label=lst:cluster, caption={Die Struktur \code{Cluster} vereint die Definition eines Clusters mit der eines Clusterbaumes.}, numbers=none]
struct _Cluster{
  bodies *bodies;             //related bodies
  int id;                     //id of the Cluster
  int start;                  //start index of the according subarray
  int n;                      //number of bodies in this Cluster
  double a[3];                //"upper left" corner of the bounding box
  double b[3];                //"lower right" corner of the bounding box
  double center[3];           //center of the bounding box
  double diam;                //diameter of the bounding box
  double *m;                  //substitution masses
  double *F;                  //substitution forces
  double *xs;                 //coordinates of the locations of submasses
  int num_sons;               //number of son clusters
  struct _Cluster *son[2];    //pointers to the son
};
typedef struct _Cluster Cluster;
    \end{lstlisting}
    \end{subfigure}
    \end{figure}
    
    \subsubsection{Die Datenstruktur}
    Die Datenstruktur speichert die für die Cluster notwendigen Daten sowie jeweils Zeiger auf die Sohncluster \code{Cluster *son[2]}. Jedes \code{Cluster} verweist auf die zum Baum gehörenden 
    \code{bodies *bodies}, und nutzt einen Startindex \code{int start} sowie die Anzahl \code{int n}, um auf die zum Cluster gehörigen Sonnen zu verweisen und zuzugreifen. Auch denkbar wäre es,
    nicht getrennt das \code{bodies}-Array und den Startindex zu speichern, sondern direkt auf das erste Element des zum Cluster gehörenden Teilarrays zu zeigen. Für jedes Cluster ein eigenes
    Array anzulegen würde hingegen zu Redundanz und somit unnötigem Speicherbedarf führen, da jede Ebene des Clusterbaumes eine Partition von $\Omega$ erzeugt. Die hier vorgestellte Variante
    erscheint mir am vielseitigsten, ohne nennenswert unnötig Speicher zu belegen.
    
    Außerdem enthält das Cluster die die Elemente des Clusters umschließende bounding box (vgl. \hyperref[w:bbox]{Seite} \pageref{w:bbox}). Diese wird durch zwei Punkte in der Gestalt 
    von \code{double a[3]} und \code{double b[3]} aufgespannt. 
    Da das Zentrum mehrfach bei der Konstruktion und Teilung auftaucht ist dieses zur Laufzeitoptimierung in \code{double center[3]} abgespeichert.
    Ebenso ist der Durchmesser der bounding box in \code{double diam} hinterlegt, um ihn nur einmal bei der Konstruktion und nicht bei jeder Abfrage erneut berechnen zu müssen.
    
    Die drei Arrays \code{double *m}, \code{double *F} und \code{double *xs} repräsentieren die in den Clustern genutzten Ersatzkörper. In \code{*m} sind die \code{n} Massen, in \code{*F} 
    Ersatzkräfte und in \code{*xs} die Positionen der Ersatzkörper, beziehungsweise Interpolationspunkte $\xi_{\mathfrak{g}, \mathfrak{i}}$, gespeichert. Für jeden Interpolationspunkt muss
    eine Ersatzmasse gespeichert werden können, sodass \code{*m} $k^3$ Einträge hat.
    Da \code{*F} ein Array von dreidimensionalen Vektoren ist, enthält es $3 k^3$ Einträge. Zwar sind \code{*xs} ebenfalls dreidimensionale Punkte, jedoch bilden diese ein regelmäßiges Raster. Indem
    wir die Koordinatenprojektionen der Punkte speichern, reichen $3 k$ Einträge. Die Interpolationspunkte können dann durch 
    $\{\tcode{xs}_0, \dots ,\tcode{xs}_{k-1}\} \times \{\tcode{xs}_0, \dots ,\tcode{xs}_{k-1}\} \times \{\tcode{xs}_0, \dots ,\tcode{xs}_{k-1}\}$ rekonstruiert werden.
    Die Einträge sind jeweils nach Koordinatenrichtung zusammengefasst, also erst alle x-Koordinaten, dann die y-Koordinaten usw.. Dies bildet wieder eine 
    ``\hyperref[w:aos]{struct of arrays}``-Struktur, um eine einfache Vektorisierung zu ermöglichen.
    
    Die Membervariable \code{int num\_sons} dient in diesem Fall der einfacheren Abfrage, ob es sich bei dem Cluster um ein Blatt oder einen inneren Knoten handelt. In allgemeineren Kontexten 
    ist es durchaus möglich, dass Cluster unterschiedlich viele Sohncluster haben. Beispielweise hat der zugehörige Blockbaum $T_{\Omega \times \Omega}$ vier Sohnblöcke pro Nicht-Blattblock. 
    
    \subsubsection{Die Konstruktion}
    \label{sec:konstr}
    \input{chapters/clustercode}
    Nun, da wir eine Datenstruktur für Clusterbäume definiert haben, müssen wir diesen noch erzeugen. Sei dazu eine \code{bodies} Struktur mit zufällig generierten Sonnen gegeben.
    
    Nun beginnen wir, indem wir ein Wurzelcluster $root$ mit $\tcode{id}_root = 0$ konstruieren. Per Definition enthält es alle in \code{bodies} gegebenen Sonnen, womit die Member \code{*bodies}, \code{start} und 
    \code{n} bereits festgelegt sind. Als nächstes erzeugen wir für die gegebenen Sonnen eine bounding box mit minimalen Ausmaßen. Dazu fassen wir für jede Koordinatenrichtung die kleinsten 
    (beziehungsweise größten) Positionswerte der \code{bodies} in \code{a} (beziehungsweise \code{b}) zusammen. Alternativ könnte man, wegen der zufälligen Konstruktion der Sonnen, auch dessen 
    Grenzen als bounding box wählen. Zu dieser bounding box werden nun die Werte \mbox{\code{center[3]}} und \code{diam} berechnet. Die Member \code{double *m} und \code{double *F} bleiben mit $0$ 
    inizialisiert. Die Interpolationspunkte \code{xs} werden allerdings ebenfalls jetzt berechnet. Dazu wurden beim Start des Programmes bereits Tschebyscheff-Interpolationspunkte auf dem Intervall 
    $[-1,1]$ berechnet. Diese werden jetzt für jede Koordinatenrichtung $\iota$ auf das entsprechende Intervall $[a_\iota, b_\iota]$ des Quaders der bounding box transformiert.
    
    Um nun mit dieser Wurzel einen Clusterbaum zu konstruieren, unterteilen wir ein Cluster jeweils in Sohncluster bis eine Abbruchbedingung erfüllt ist. 
    Die wichtigsten Auszüge aus dem Code zur rekursiven Konstruktion des Clusterbaumes sind in \autoref{lst:setup}, \autoref{lst:init} und \autoref{lst:sort} aufgeführt.
    
    Da wir mit zufällig generierten und recht großen Datenmengen arbeiten, ist es nicht notwendig, die Unterteilung eines Clusters in Sohncluster kardinalitätsgesteuert vorzunehmen, um ein gutes load 
    balancing zu erhalten. Dies könnte bei reellen Daten möglicherweise notwendig werden, wenn es in der betrachteten Menge $\Omega$ große Bereiche mit sehr wenigen Körpern gibt. 
    Der hier vorgestellte Algorithmus unterteilt die Cluster auf jeder Stufe des Baumes rein geometrisch durch eine Mittelebene. Dazu wird zunächst die Richtung der größten Ausdehnung der bounding
    box bestimmt und dann in dieser Koordinatenrichtung mittig unterteilt. Während dieser Unterteilung werden die zunächst ungeordneten \code{bodies} gemäß ihrer Zugehörigkeit zu einem der beiden
    Sohncluster sukzessive sortiert.
    
    Die Methode \code{\_sortIndices} beruht, über die gesamte Konstruktion des Clusterbaumes betrachtet, auf der Grundidee von Quicksort. Für die größte Richtung $[a_\iota, b_\iota]$
    des Quaders, der die bounding box darstellt, wird als Quasi-Pivotelement jeweils die Mitte $c_\iota = \frac{a_\iota + b_\iota}{2}$ dieser Richtung gesetzt und die Sonnen entsprechend ihrer 
    Position in die linke oder rechte Hälfte einsortiert. Anders als bei Quicksort wird auf Grund der gewählten Abbruchbedingung die Liste nicht vollständig sortiert. Für den Algorithmus ist
    die Zugehörigkeit der Sonnen zu bestimmten Clustern die entscheidende Information.
    
    Nach \hyperref[def:clusterbaum]{Definition}\autoref{def:clusterbaum} wurden zwei Beispiele für Abbruchbedingungen erwähnt. Wegen der zufälligen Generierung lässt sich die ungefähre Anzahl Elemente
    in den Blattclustern anhand der Tiefe des Baumes schätzen. Indem wir als Abbruchbedingung eine maximale Tiefe für den Clusterbaum festlegen, stellen wir gleichzeitig sicher, dass der Clusterbaum
    ein vollständiger Binärbaum wird.
    Der Wert \code{MAX\_DEPTH} für die Abbruchbedingung wird gleich zu Beginn des Programmlaufs auf Basis der Anzahl an Sonnen ($|\Omega| = 2^{\tcode{pot}}$) und der Interpolationsordnung $k$ 
    berechnet. Dabei gilt:
    \begin{equation}
      \tcode{MAX\_DEPTH} := \tcode{pot} - \mathfrak{l}, \ \ \ \ \ \ \ \ \ \ \ \ 
      \mathfrak{l} :=
      \begin{cases}
	\lceil \log_2(2 k^3) \rceil & \text{falls } k > 1\\
	4			    & \text{falls } k = 1
      \end{cases}
      \label{eq:l}
    \end{equation}
    Bei einer Baumtiefe von \code{pot} wären die Blattcluster im Schnitt gerade einelementig. Indem die Abbruchbedingung die Tiefe des Clusterbaumes auf $\tcode{pot} - \mathfrak{l}$ begrenzt,
    enthalten die Blattknoten im Schnitt gerade $2^\mathfrak{l}$ Elemente.
    Durch diese Baumtiefenregulierung wird für $k > 1$ die nächsthöhere Zweierpotenz zur doppelten Anzahl an Interpolationspunkten als durchschnittliche Anzahl Sonnen pro Blattcluster festgelegt. 
    Für die Interpolationsordnung $k = 1$ wäre dies eine zu feine Zerlegung. Daher wird hier $\mathfrak{l}$  auf den Wert $4$ und damit die durchschnittliche Blattgröße auf $2^4 = 8$ gesetzt.
    Indem die Blattgröße im Schnitt auf ungefähr das Doppelte der Anzahl an Interpolationspunkten festgelegt wird, soll eine gute Balance zwischen Genauigkeit und Laufzeit erreicht werden.
        
    Für die Blattcluster ist keine eigene setup-Methode notwendig, da der Konstruktor \mbox{\code{\_new\_bound\_Cluster(...)}} zunächst alle Werte für ein Blattcluster setzt. Die Methode \linebreak
    \mbox{\code{\_setup(...)}} entscheidet also anhand der Stufe ob ein Cluster ein Blattcluster bleibt, oder durch Unterteilung zu einem Nicht-Blattcluster wird.

    \subsection{Vorwärtstransformation}
    \label{sec:vorw}
    \input{chapters/forw}
    Nun können wir uns an die Berechnung der Gravitation machen.
    Um eine Matrix-Vektor-Multiplikation mit der Matrix $\tilde F$ auf zulässigen Blöcken auszuwerten, muss diese Operation als erstes auf den Matrizen $W_\sigma$ ausgewertet werden.
    Die Auswertung der Matrizen $W_\sigma$ nennt man auch \textit{Vorwärtstransformation}.
    
    Da wir die Gravitationskräfte für alle Sonnen in $\Omega$ berechnen wollen, ist es sinnvoll die Vorwärtstransformation einfach für alle $\sigma \in T_\Omega$ durchzuführen. Dies geschieht
    im vorliegenden Programm durch einen Aufruf von \code{forward(Cluster *c)} mit $root(T_\Omega)$.
    Die Methode \code{forward(...)} unterscheidet zwischen Blatt- und Nicht-Blattclustern, und ruft entsprechend die Methode \code{\_forward\_Leaf(Cluster *c)} oder \code{\_forward\_nonLeaf(Cluster *c)}
    auf. Die Methode \code{\_forward\_Leaf(...)} entspricht der Konstruktion und Auswertung der Matrizen $W_\sigma$ anhand der Sonnen $x \in \sigma$, die Methode \code{\_forward\_nonLeaf(Cluster *c)} 
    der anhand der Sohncluster.
    Für letztere müssen daher die Ergebnisse der Söhne bereits vorliegen. Daher ruft diese als ersten Schritt \code{forward(cs)} für alle Sohncluster \code{cs} auf. Auf diese Weise durchlaufen die 
    Methoden gemeinsam betrachtet den Clusterbaum rekursiv. Der Code der drei Methoden ist in \autoref{lst:forw}, \autoref{lst:forwnonleaf} und \autoref{lst:forwleaf} zu finden.
    
    Durch die Methode \code{\_forward\_Leaf(Cluster *c)} werden, wie auf \hyperref[w:ersatzmassen]{Seite} \pageref{w:ersatzmassen} beschrieben, für alle Interpolationspunkte 
    $\xi_{\tcode{c}\mu} \in \bigtimes_{i=0}^2 \{\tcode{xs}_{i \cdot k}, \dots ,\tcode{xs}_{(i+1) \cdot k-1}\}, \mu \in M$ durch
    \[
      \tcode{m}_{\xi_{\tcode{c}\mu}} = \tcode{m}_\mu := \sum_{y \in \tcode{c}} \lag_{\tcode{c},\mu}(y) m_y
    \]
    die Ersatzmassen in der Clusterbasis berechnet und gespeichert. Die Methode \code{_forward\-_nonLeaf(Cluster *c)} berechnet ebenfalls Ersatzmassen, jedoch nicht aus allen Sonnen des Clusters,
    sondern aus den Interpolationspunkten und Ersatzmassen der Sohncluster (vgl. \autoref{sec:transmat}).
    
    Stellt man sich den Baum von der Wurzel aus nach unten hängend vor, werden also die Massen der Sonnen in den Baum hochgezogen. Je höher die Stufe des Baumes, um so gröber ist die Approximation.
    
    
    \subsection{Auswertung der Kopplungsmatrizen}
    \label{sec:kopplung}
    Der nächste Schritt in der Auswertung ist die Multiplikation mit den Kopplungsmatrizen $S_b$. Da diese Matrizen, im Gegensatz zu den Clusterbasen $V_\tau$ und $W_\sigma$, vom Block und damit
    von beiden und nicht nur von einem Cluster abhängen, müssen wir nun den Blockbaum $T_{\Omega \times \Omega}$ durchlaufen. 
    Gleichzeitig können wir in diesem Schritt die Nahfeldmatrizen $N_b$, die ebenfalls von den Blöcken abhängen, auswerten. 
    
    Den Blockbaum haben wir nicht explizit aufgestellt. Das ist auch nicht notwendig, da wir ihn implizit konstruieren können und somit keinen Speicherplatz benötigen.
    Wir durchlaufen unseren impliziten Blockbaum, indem wir, beginnend mit dem Wurzelblock $b_{root} = root(T_\Omega) \times root(T_\Omega)$, für jeden Block $b = \tau \times \sigma$ prüfen, ob
    \begin{enumerate}
      \item $\mathcal{Z}_\eta(\tau,\sigma) = \ttit{zulässig}$ erfüllt ist. Ist dies der Fall, haben wir, unabhängig davon, ob $\tau \in \mathcal{L}(T_\Omega)$ oder 
      $\sigma \in \mathcal{L}(T_\Omega)$ gilt, einen Blattblock erreicht und können $S_b$ auswerten. 
      \item Ist $\mathcal{Z}_\eta(\tau,\sigma) = \ttit{unzulässig}$, prüfen wir, ob 
      \begin{enumerate}
	\item $\tau, \sigma \in \mathcal{L}(T_\Omega)$. Falls $\tau$ und $\sigma$ Blattcluster sind, haben wir ebenfalls einen Blattblock erreicht, können aber nicht approximieren und müssen
	daher $N_b$ auswerten.
	\item Sind $\tau$ und $\sigma$ aber keine Blattcluster, so können wir durch folgende Zuweisung rekursiv fortfahren:	
      \end{enumerate}
    \end{enumerate}
    Für $\tilde \tau_0 \neq \tilde \tau_1 \in sons(\tau)$ und $\tilde \sigma_0 \neq \tilde \sigma_1 \in sons(\sigma)$ definieren wir Sohnblöcke
    \begin{align*}
      \tilde b_0 := \tilde \tau_0 \times \tilde \sigma_0 & \ \ \ \ \ \ \ \ \ \ \ \ & \tilde b_1 := \tilde \tau_0 \times \tilde \sigma_1\\
      \tilde b_2 := \tilde \tau_1 \times \tilde \sigma_0 & \ \ \ \ \ \ \ \ \ \ \ \ & \tilde b_3 := \tilde \tau_1 \times \tilde \sigma_1.
    \end{align*}
    
    Durch dieses Vorgehen konstruieren wir implizit einen streng zulässigen Blockbaum. Zulässige Blöcke werden automatisch Blattblöcke, da die Rekursion dort nicht fortgesetzt wird.
    Außerdem werden die Sohnblöcke immer aus genau einer Stufe des Clusterbaumes gebildet, bei welchem wir sichergestellt haben, dass er als vollständiger Binärbaum konstruiert wird. 
    Daher ist auch sichergestellt, dass unzulässige Blattblöcke nur aus Blättern des Clusterbaumes bestehen können.
    
    \begin{figure}[tb]
    \begin{subfigure}{0.9\textwidth}
    \begin{lstlisting}[label=lst:eval, caption={Durch diese rekursive Struktur wird ein impliziter Blockbaum durchlaufen, um die Matrizen $S_b$ bzw. $N_b$ auszuwerten.}]
void _eval(Cluster *ct, Cluster *cs){
  if(admissable(ct, cs)){
      _eval_CC(ct, cs);
  } else {
    if (ct->num_sons && cs->num_sons){	//both clusters have sons left:
      _eval(ct->son[0], cs->son[0]);
      _eval(ct->son[0], cs->son[1]);
      _eval(ct->son[1], cs->son[0]);
      _eval(ct->son[1], cs->son[1]);
    } else {                          	//no son clusters left but still not admissable:
      _eval_full(ct, cs);
    }
  }
  // world.rank?:current_level?:printf("\nfirst admissable block on level %d\n", first_admissable);
  // world.rank?:current_level?:printf("split depth: %d\n", SPLIT_DEPTH);
}
    \end{lstlisting}
    \end{subfigure}
    \end{figure}
    
    Für jeden Blattblock $b = \tau \times \sigma$ wird also
    \begin{enumerate}
     \item für alle $x \in \tau$ und $y \in \sigma$ die Funktion $f$ ausgewertet und direkt in den \code{bodies} gespeichert, falls $b$ unzulässig ist, oder
     \item für alle Interpolationspunkte $\xi_\indt{\nu} \text{, } \xi_\indt{\nu}$, mit $\nu,\mu \in M$ der Ausdruck $P(\xi_\indt{\nu} , \xi_\indt{\nu})$ ausgewertet und mit den in der 
     \vorw berechneten Ersatzmassen $\tcode{m}_\mu$ multipliziert, falls $b$ zulässig ist.
    \end{enumerate}
    
    Anschaulich werden in diesem Schritt in den zulässigen Blöcken aus den Ersatzmassen und Interpolationspunkten Quasi-Ersatzkräfte\footnote{An dieser Stelle wird nur die 
    Masse des Source-Clusters $\sigma$ verrechnet. Daher handelt es sich im physikalischen Sinne noch nicht um eine Kraft.} berechnet. 

    \subsection{Rückwärtstransformation}
    \label{sec:rückw}
    Der letzte Schritt der Berechnung ist die Auswertung der Matrizen $V_\tau$. Diesen Schritt nennt man auch \textit{Rückwärtstranformation}.
    
    Auch dieser Schritt hängt wieder ausschließlich von den Clustern ab. Daher kann die Rückwärtstranformation wieder unabhängig von den Blöcken für den gesamten Clusterbaum $T_\Omega$ ausgeführt
    werden. Wir rufen dazu wieder mit $root(T_\Omega)$ die Methode \code{backward(Cluster *c)} auf. Wie bereits bei der \vorw unterscheidet diese Methode, ob es sich bei
    dem aktuellen Cluster um ein Blatt- oder ein Nicht-Blattcluster handelt und delegiert die Arbeit entsprechend an die Methoden \code{\_backward\_Leaf(Cluster *c)} und 
    \code{\_backward\_nonLeaf(Cluster *c)}. Anders als bei der \vorw müssen bei der Rückwärtstransformation die Ergebnisse des Vaterclusters für die Söhne vorliegen. Daher gibt die
    Methode \code{_backward_nonLeaf(Cluster *c)} die approximierten Quasi-Kräfte, gewichtet über die Lagrange-Polynome, an die Sohncluster weiter. Für alle Söhne $\tilde{\tcode{c}} \in sons(\tcode{c})$
    und alle $\mu \in M$ wird
    \[
      \tcode{F}_{\tcode{c},\tilde{\tcode{c}},\mu} = \sum_{\nu \in M} \lag_{\tcode{c},\nu}(\xi_{\tilde{\tcode{c}},\mu} \tcode{F}_{\tcode{c},\nu}
    \]
    zu den dort eventuell bereits aus der \koppl vorhandenen Quasi-Ersatzkräfte addiert.
    
    Schließlich werden in der Methode \code{_backward_Leaf(Cluser *c)} die Quasi-Ersatzkräfte $\tcode{F}_{\tcode{c},\nu}$, $\nu \in M$ über die Lagrange-Polynome gewichtet auf alle Sonnen 
    $x \in \tcode{c}$ verteilt und mit deren Masse $m_x$ multipliziert. Da auch hier bereits aus der Nahfeldauswertung Kräfte vorhanden sind, müssen diese approximierten Kräfte\footnote{Durch die
    Multiplikation mit $m_x$ werden die Quasi-Kräfte im physikalischen Sinne zu Kräften vervollständigt.} zu den vorhandenen addiert werden.
    
    Da diese Methoden analog zu denjenigen der Vorwärtstransformation funktionieren sind diese hier nicht aufgeführt.

  \clearpage